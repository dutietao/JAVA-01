BIO与NIO的理解

例子：

1 系统从socket读取数据
2 系统从磁盘读取数据到内存

Linux系统对于上述的1视为block，而对于上述的2视为不是block， 严格区分磁盘block和网络block

BIO

对于网络应用中，如果对方的数据没有传送过来，那么读取方必须等待

对于单线程服务，只能卡死等待，在这期间是没办法做任何事情。

对于多线程服务，每个线程必须创建一个context，线程上下文的切换成本高，另外每个线程的逗占用一定的空间作为线程栈

NIO

在BIO下，如果数据没有到达则会直接block住，而在NIO下如果数据没有到达则直接返回

1）：第一种场景，不断轮询，看看数据有没有到达，有就处理，没有则等待一会继续轮询
缺点：如果有多个线程在等待，需要跟多的上下文切换；另外一个数据到达不可预期，不知道需要等待多久

2）：第二种场景，对于第一种场景要是能有操作系统告诉程序就好了。IO多路复用就是这种场景下搞出来的。
IO多路复用的关键理解
a IO多路复用指的是数据流共享多个socket，操作系统一起监控他们
b IO多路复用的API调用是BLOCK的（select，poll，epoll）
c IO多路复用解决了调度问题，并不能解决网络IO

select

select监听了一个文件描述符数组，不断循环检测每个对应的数据是否到达，到达则处理
缺点：
select能够支持的最大的fd数组的长度是1024
fd数组按照监听的事件分为了3个数组，为了这3个数组要分配3段内存去构造，而且每次调用select前都要重设它们（因为select会改这3个数组)；调用select后，这3数组要从用户态复制一份到内核态；事件到达后，要遍历这3数组。很不爽。
select返回后要挨个遍历fd，找到被“SET”的那些进行处理。这样比较低效。
select是无状态的，即每次调用select，内核都要重新检查所有被注册的fd的状态。select返回后，这些状态就被返回了，内核不会记住它们；到了下一次调用，内核依然要重新检查一遍。于是查询的效率很低

poll

poll针对select有一些优化，主要是数组上限，不需要重设
缺点：
同样是无状态的，因从接收到数据后需要拷贝到用户内存区域，不知道那个是有数据的，依然需要重新遍历


epoll

epoll进一步优化了上述api调用
epoll是有状态的，避免了数据复制，操作系统层面标记已经发生的数据

详情：https://blog.csdn.net/vtopqx/article/details/88115899